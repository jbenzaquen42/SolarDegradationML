{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c9880e",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning Process\n",
    "\n",
    "This notebook outlines the data cleaning process for the solar panel degradation analysis project. \n",
    "The steps include handling missing values, correcting data types, and dealing with outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c1139",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Handling Missing Values\n",
    "\n",
    "Missing values can significantly impact the quality of the analysis. \n",
    "The strategy for handling missing data depends on the nature of the data and its relevance to the study.\n",
    "For columns with a high percentage of missing values that are crucial for analysis, \n",
    "it might be more appropriate to remove these rows. \n",
    "For others, imputation or retaining the missing values could be considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e190640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identifying columns with missing values and the count of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Decision: Drop rows with missing 'technology1' and 'technology2' if they are crucial for analysis\n",
    "df_cleaned = df.dropna(subset=['technology1', 'technology2'])\n",
    "\n",
    "# Impute or further handle other missing values as deemed necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32665d58",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Correcting Data Types\n",
    "\n",
    "Correct data types are essential for effective analysis. \n",
    "This step ensures that numerical data is treated as such and categorical data is recognized by analysis tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correcting data types\n",
    "# Converting 'length_years_rounded' to numerical type (float)\n",
    "df_cleaned['length_years_rounded'] = pd.to_numeric(df_cleaned['length_years_rounded'], errors='coerce')\n",
    "\n",
    "# Converting 'tracking' to boolean\n",
    "df_cleaned['tracking'] = df_cleaned['tracking'].astype('bool')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd508b",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Handling Outliers\n",
    "\n",
    "Outliers can skew the analysis and may need to be treated separately. \n",
    "This step involves identifying outliers and deciding on a strategy to handle them, such as removal or further investigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identifying outliers in 'plr_median' using IQR\n",
    "Q1 = df_cleaned['plr_median'].quantile(0.25)\n",
    "Q3 = df_cleaned['plr_median'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtering out the outliers\n",
    "df_cleaned = df_cleaned[(df_cleaned['plr_median'] >= lower_bound) & (df_cleaned['plr_median'] <= upper_bound)]\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
